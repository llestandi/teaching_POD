{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f215e11-ebe2-489d-a8e1-c66480141399",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee31d0-f33f-470a-a97c-951ae09f1895",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Singular value decomposition is similar to eigen value decomposition in the sense that it yields orthonormal bases and values associated with the matrix at hand. It is more genral as it applies to rectangular matrices. For any matrix $A \\in \\mathbb{R}^{n \\times m}$, it reads\n",
    "$$A=U\\Sigma V^T$$\n",
    "where $U \\in \\mathbb{R}^{n \\times n}$, $\\Sigma$ is a diagonal matrix of the same size of A and $V \\in \\mathbb{R}^{m \\times m}$, $\\Sigma$. $U$ and $V$ are orthonormal matrices which columns are bases of the spaces associated with each dimension of A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a6891-3f50-472b-81ce-df027f729760",
   "metadata": {},
   "source": [
    "### SVD based approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f1a1c-a4a5-41b7-a0d1-4154b458b7c6",
   "metadata": {},
   "source": [
    "By construction (see literature), SVD provides the best rank $k$ approximation of matrix A in the sense of $L^2$ norm. Indeed, the singular values $\\sigma_i$ are sorted in a decreasing order i.e. $\\forall j>i, \\sigma_i>\\sigma_j$. Then, we have\n",
    "$$A\\approx A_k = \\sum_{i=0}^k \\sigma_i u_i \\otimes v_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653c492-3e51-4034-b178-35f0846a3a82",
   "metadata": {},
   "source": [
    "### SVD is related to EVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff423d43-b3e1-4178-b368-a7da2140ba0b",
   "metadata": {},
   "source": [
    "Given the properties of the SVD, we can see that it is possible to solve an EVD problem that is equivalent to solve SVD. Indeed,\n",
    "$$AA^T=U\\Sigma V^T V \\Sigma U^T =U\\Sigma^2 U^T  $$ which means U and $\\Sigma^2$ are the solution of the EVD of $AA^T$.\n",
    "\n",
    "The same can be done with $A^TA=V\\Sigma^2V^T$. Then one can take advantage of the size of the problem if $n >> m$ or the opposite. This also allows one to use the so called power iteration method to compute only the first few modes of the SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcaa3c-06cf-4f78-bcd4-33e8b7ab100e",
   "metadata": {},
   "source": [
    "### Computing SVD\n",
    "There are multiple algorithms to cumpute SVD of both dense and sparse matrices. Most languages compatible with scientific computing (python, mathlab, C++, fotran,...) have highly efficient libraries to compute SVD on a single machine. Used well, they can use multi-core units and GPUs when available.\n",
    "\n",
    "Alternatively, one will be able to use EVD solvers when the problem is suitable.\n",
    "\n",
    "In case of very large matrices, one will have to use more advanced method to solve the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72ce9f-a72a-4777-b374-a4f2cdbe75f8",
   "metadata": {},
   "source": [
    "## Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946820f-2d2f-4f65-a5a7-7cf48d389160",
   "metadata": {},
   "source": [
    "With the programming language of your choice (python/matlab recommended), solve the following exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bf621-271b-4be4-b47b-cabde4b9b4dc",
   "metadata": {},
   "source": [
    "1. For a function that can be either $f(x,y)=xy$ or $f(x,y)=\\sin(\\sqrt{x^2+y^2})$, create a 50 by 200 sampling grid on the unit domain $[0,1]\\times [0,1]$ and fill a matrix with the values. Then visualize the matrix using the software of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5dc18d-ebd0-4e37-9915-80106d9a2461",
   "metadata": {},
   "source": [
    "2. Apply direct SVD from a computing library compatible with (or embedded in) your language. You will have to find out what's the basic computing library used, which algorithm is called and briefly describe its algorithm with pros and cons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49708793-d548-4ef6-a92e-953b3796d613",
   "metadata": {},
   "source": [
    "3. Compute approximation error (L2) defined as $E(A,A_k)=\\frac{||A-A_k||_{L^2}}{||A||_{L^2}}$ with various truncation rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc47e2b-493a-4bac-a956-261652c27fe7",
   "metadata": {},
   "source": [
    "4. Plot the error vs $k$ graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ed5f8-82f9-4677-baee-507d23bb6fc1",
   "metadata": {},
   "source": [
    "5. Redo the exercice with a large image of your choice after converting it to grayscale. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d6f7c-ab68-4e6e-af73-3847bcaf6064",
   "metadata": {},
   "source": [
    "6. Add a timer to the SVD call and compare the algorithm based on EVD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
